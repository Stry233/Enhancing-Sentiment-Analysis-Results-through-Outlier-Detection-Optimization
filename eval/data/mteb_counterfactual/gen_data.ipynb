{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9091d0b-4213-46db-85da-65b0760c8277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: amazon_counterfactual/en\n",
      "Found cached dataset amazon_counterfactual (/home/yuetian/.cache/huggingface/datasets/mteb___amazon_counterfactual/en/1.0.0/3b6ae425288b4ec49ffa16445fa595593e9c00e210da62c9cf576ad2acfe4a8b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc5e5a74cd3458cb20857b136ab3815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"mteb/amazon_counterfactual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b015b49f-04b0-4f14-a44d-4ffebae082e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'train' and 'test' subsets into pandas DataFrames\n",
    "train_df = dataset['train'].to_pandas()\n",
    "test_df = dataset['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f491c3b6-d2fa-43dc-9fcb-63e1f06696d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\")\n",
    "test_df.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd47b78d-f77f-4791-a33d-8fc3bd50273b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    539\n",
       "1    131\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cca97487-5ec9-4e05-9b98-5879e4d2cdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.2_test.csv', '0.4_test.csv', '0.6_test.csv', '0.8_test.csv', '1_test.csv']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def generate_data(threshold, dataframe, dataset):\n",
    "    mask = []\n",
    "    class_num = 0\n",
    "\n",
    "    # Iterate over class directories until no more are found\n",
    "    while True:\n",
    "        class_dir = os.path.join('..', '..', 'score', dataset+\"_eval\", f'class{class_num}')\n",
    "\n",
    "        # If the directory doesn't exist, break the loop\n",
    "        if not os.path.exists(class_dir):\n",
    "            break\n",
    "\n",
    "        file_path_class = os.path.join(class_dir, f'mask_class{class_num}.json')\n",
    "        loaded_predicted_class = load_json(file_path_class)\n",
    "        mask_class = [score[0] for score in loaded_predicted_class if score[2] < threshold]\n",
    "        mask.extend(mask_class)\n",
    "        \n",
    "\n",
    "        class_num += 1\n",
    "\n",
    "    # Merge the masks and remove duplicates\n",
    "    mask = list(set(mask))\n",
    "\n",
    "    # Filter the DataFrame based on the index list\n",
    "    filtered_df = dataframe.loc[mask].dropna()\n",
    "\n",
    "    # Write the filtered DataFrame to a new CSV file\n",
    "    data_dir = os.path.join(f\"{threshold}_test.csv\")\n",
    "    filtered_df.to_csv(data_dir, index=False)\n",
    "\n",
    "    return data_dir\n",
    "\n",
    "def generate_threshold_data(thresholds: list, ground_truth: pd.DataFrame, dataset: str) -> list:\n",
    "    \"\"\"Generates data for each threshold.\"\"\"\n",
    "    filenames = []\n",
    "    for threshold in thresholds:\n",
    "        filename = generate_data(threshold, ground_truth, dataset)\n",
    "        filenames.append(filename)\n",
    "    return filenames\n",
    "\n",
    "\n",
    "generate_threshold_data([0.2, 0.4, 0.6, 0.8, 1], pd.read_csv(\"./test.csv\"), \"mteb_counterfactual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92ccc477-a076-407b-8e03-7d9ec3e69a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"1_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb02de99-6ae2-4b1b-9b34-d894202b4288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    538\n",
       "1    130\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6e518d4-4965-4faa-bf90-66159e5c127f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert-base-uncased has 66362880 parameters.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"  # Replace with your desired model name\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "num_params = model.num_parameters()\n",
    "print(f\"{model_name} has {num_params} parameters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fc184cb-ec5a-45fe-9363-ddaf7626de6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/deberta-v3-large has 434012160 parameters.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model_name = \"microsoft/deberta-v3-large\"  # Replace with your desired model name\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "num_params = model.num_parameters()\n",
    "print(f\"{model_name} has {num_params} parameters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c95aa35-76a0-428c-9cbd-4a657f13458b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_GPU",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
